# CUDA笔记



## CUDA基础学习笔记

ref：[人工智能编程 | 谭升的博客 (face2ai.com)](https://face2ai.com/program-blog/#GPU编程（CUDA）)



## 1 异构并行计算

### 1.0 并行计算与计算机架构

#### 1 并行计算

并行计算其实涉及到两个不同的技术领域：

- 计算机架构（硬件）
- 并行程序设计（软件）

这两个很好理解，一个生产工具，一个用工具产生各种不同应用。

- 硬件主要的目标：为软件提供更快的计算速度，更低的性能功耗比，硬件结构上支持更快的并行。
- 软件的主要目的：使用当前的硬件压榨出最高的性能，给应用提供更稳定快速的计算结果。

##### 并行性

写并行程序主要是分解任务，我们一般把一个程序看成是指令和数据的组合，当然并行也可以分为这两种：

- 指令并行
- 数据并行

我们的任务更加关注**数据并行**，所以我们的主要任务是：分析数据的相关性，哪些可以并行，哪些不能不行。

>
> 如果你对并行不太了解，可以先去学习学习pThread和OpenMP，了解下载多核CPU上是怎么并行的，比如把用openmp把for并行。

我们研究的是大规模数据计算，计算过程比较单一（不同的数据基本用相同的计算过程）但是数据非常多，所以我们主要是数据并行，分析好数据的相关性，决定了我们的程序设计。CUDA非常适合数据并行。

**数据并行**程序设计，首先需要：**把数据依据线程进行划分**

1. 块划分：把一整块数据切成小块，每个小块随机的划分给一个线程，每个块的执行顺序随机；
2. 周期划分：线程按照顺序处理相邻的数据块，每个线程处理多个数据块，比如有五个线程，线程1执行块1，线程2执行块2，...，线程5执行块5，线程1执行块6...

> 不同的数据划分严重影响程序性能，所以针对不同的问题和不同计算机结构，我们要通过和理论和试验共同来决定最终最优的数据划分。



#### 2 计算机架构

##### Flynn’s Taxonomy

划分不同计算机结构的方法有很多，广泛使用的一种被称为佛林分类法Flynn’s Taxonomy，他根据**指令和数据进入CPU的方式**分类，分为以下四类：

- 单指令单数据SISD（传统串行计算机，386）
- 单指令多数据SIMD（并行架构，比如向量机，所有核心指令唯一，但是数据不同，现在CPU基本都有这类的向量指令）
- 多指令单数据MISD（少见，多个指令围殴一个数据）
- 多指令多数据MIMD（并行架构，多核心，多指令，异步处理多个数据流，从而实现空间上的并行，MIMD多数情况下包含SIMD，就是MIMD有很多计算核，计算核支持SIMD）



为了提高并行的计算能力，我们要从架构上实现下面这些性能提升：

- **降低延迟**：**延迟**是指<u>操作从开始到结束所需要的时间</u>，一般用微秒计算，延迟越低越好。
- **提高带宽**：**带宽**是<u>单位时间内处理的数据量</u>，一般用MB/s或者GB/s表示。
- **提高吞吐量**：**吞吐量**是<u>单位时间内成功处理的运算数量</u>，一般用gflops来表示（十亿次浮点计算），吞吐量和延迟有一定关系，都是反应计算速度的，一个是时间除以运算次数，得到的是单位次数用的时间–延迟，一个是运算次数除以时间，得到的是单位时间执行次数–吞吐量。

##### 根据内存划分

计算机架构也可以根据内存进行划分：

1. **分布式内存**的多节点系统
2. **共享内存**的多处理器系统

第一个更大，通常叫做集群，就是一个机房好多机箱，每个机箱都有内存处理器电源等一些列硬件，通过网络互动，这样组成的就是分布式。

第二个是单个主板有多个处理器，他们共享相同的主板上的内存，内存寻址空间相同，通过PCIe和内存互动。多个处理器可以分多片处理器，和单片多核（众核many-core），也就是有些主板上挂了好多片处理器，也有的是一个主板上就一个处理器，但是这个处理器里面有几百个核。

GPU就属于众核系统。当然现在CPU也都是多核的了，但是他们还是有很大区别的：

- CPU适合执行复杂的逻辑，比如多分支，其核心比较重（复杂）
- GPU适合执行简单的逻辑，大量的数据计算，其吞吐量更高，但是核心比较轻（结构简单）



### 1.1 异构计算与CUDA

#### 1 异构计算

##### 异构

不同的计算机架构就是异构，如CPU与GPU的架构不同。

##### 异构架构

1. **CPU**我们可以把它看做一个指挥者，主机端，host；
2. 而完成大量计算的**GPU**是我们的计算设备，device；
3. CPU和GPU之间通过PCIe总线连接，用于**传递指令和数据**，这部分也是后面要讨论的性能瓶颈之一。

一个异构应用包含两种以上架构，所以代码也包括不止一部分：

- 主机代码：在主机端运行，被编译成主机架构的机器码
- 设备代码：在设备上执行，被编译成设备架构的机器码

所以主机端的机器码和设备端的机器码是隔离的，自己执行自己的，没办法交换执行。

主机端代码主要是控制设备，完成数据传输等控制类工作，设备端主要的任务就是计算。

因为当没有GPU的时候CPU也能完成这些计算，只是速度会慢很多，所以可以把GPU看成CPU的一个加速设备。

##### 范例

CPU和GPU相互配合，各有所长，各有所短：

- 低并行、逻辑复杂的程序适合用CPU；
- 高并行、逻辑简单的大数据计算适合GPU；

CPU和GPU线程的区别：

- CPU线程是重量级实体，操作系统交替执行线程，线程上下文切换花销很大；
- GPU线程是轻量级的，GPU应用一般包含成千上万的线程，多数在排队状态，线程之间切换基本没有开销；
- CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU核则是大量线程，最大幅度提高吞吐量；

##### CUDA：一种异构计算平台

CUDA平台不是单单指软件或者硬件，而是建立在Nvidia GPU上的一整套平台，并扩展出多语言支持，CUDA C 是标准ANSI C语言的扩展，扩展出一些语法和关键字来编写设备端代码，而且CUDA库本身提供了大量API来操作设备完成计算。

对于API也有两种不同的层次，一种相对高层，一种相对底层，两种API是互斥的，只能用一个，两者之间的函数不可以混合调用，只能用其中的一个库：

- CUDA驱动API：低级的API，使用相对困难；
- CUDA运行时API：高级API使用简单，其实现基于驱动API。



一个CUDA应用通常可以分解为两部分：

- CPU 主机端代码
- GPU 设备端代码

CUDA nvcc编译器会自动分离你代码里面的不同部分，例如：

- 主机代码用C写成，使用本地的C语言编译器编译；
- 设备端代码，也就是核函数，用CUDA C编写，通过nvcc编译；
- 链接阶段，在内核程序调用或者明显的GPU设备操作时，添加运行时库。

**核函数**是我们后面主要接触的一段代码，也就是设备上执行的程序段。



##### CUDA代码示例





## 2 CUDA编程模型





CUDA编程模型是一个异构模型，需要CPU和GPU协同工作。在CUDA中，**host**和**device**是两个重要的概念。

我们用host指代CPU及其内存，而用device指代GPU及其内存。

CUDA程序中既包含host程序，又包含device程序，它们分别在CPU和GPU上运行。同时，host与device之间可以进行通信，这样它们之间可以进行数据拷贝。

典型的CUDA程序的执行流程如下：

1. 分配host内存，并进行数据初始化；
2. 分配device内存，并从host将数据拷贝到device上；
3. 调用CUDA的核函数在device上完成指定的运算；
4. 将device上的运算结果拷贝到host上；
5. 释放device和host上分配的内存。

### 3 CUDA执行模型

### 4 内存

### 5 流与并发

### 6 指令极原语言

### 7 GPU加速库

### 8 多GPU编程

### 9 注意事项
